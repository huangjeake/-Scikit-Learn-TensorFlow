'''
循环神经网络RNN：
    正向传播和反向传播
    RNN常用于语音识别，根据建立的语音模型，计算各种组合的可能性，输出概率最高的组合

    使用基于字符的语言模型有有点也有缺点，优点就是你不必担心会出现未知的标识，例如基于字符的语言模型会将Mau这样的序列也视
    为可能性非零的序列。而对于基于词汇的语言模型，如果Mau不在字典中，你只能把它当作未知标识UNK。不过基于字符的语言模型一个
    主要缺点就是你最后会得到太多太长的序列，大多数英语句子只有10到20个的单词，但却可能包含很多很多字符。所以基于字符的语言
    模型在捕捉句子中的依赖关系也就是句子较前部分如何影响较后部分不如基于词汇的语言模型那样可以捕捉长范围的关系，并且基于字
    符的语言模型训练起来计算成本比较高昂。所以我见到的自然语言处理的趋势就是，绝大多数都是使用基于词汇的语言模型。

解决梯度消失和梯度爆炸的问题：
    原因:对于当前梯度求导，根据当前梯度计算下一层的梯度
    1.采用relu、leakrelu、elu等激活函数
    2.采用batchnorm
    3.引入残差结构
    4.使用LSTM神经元，LSTM是一个比GRU更加强大和通用的版本　GRU门控循环单元

GRU和LSTM:
    GRU的优点是这是个更加简单的模型，所以更容易创建一个更大的网络，而且它只有两个门，在计算性上也运行得更快，然后它可以扩大模型的规模。
    但是LSTM更加强大和灵活，因为它有三个门而不是两个。如果你想选一个使用，我认为LSTM在历史进程上是个更优先的选择，所以如果你必须选一个，
    我感觉今天大部分的人还是会把LSTM作为默认的选择来尝试。虽然我认为最近几年GRU获得了很多支持，而且我感觉越来越多的团队也正在使用GRU，
    因为它更加简单，而且还效果还不错，它更容易适应规模更加大的问题。

双向RNN：
    这个双向RNN网络模型的缺点就是你需要完整的数据的序列，你才能预测任意位置。比如说你要构建一个语音识别系统，那么双向RNN模型需要你
    考虑整个语音表达，但是如果直接用这个去实现的话，你需要等待这个人说完，然后获取整个语音表达才能处理这段语音，并进一步做语音识别

'''